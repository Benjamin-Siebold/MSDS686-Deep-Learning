{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "Deep_Learning_'Hello_MNIST'.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Benjamin-Siebold/MSDS686-Deep-Learning/blob/main/Deep_Learning_'Hello_MNIST'.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1BMmhrW4-VF"
      },
      "source": [
        "# A tutorial introduction into deep learning with Keras and Tensorflow.  We will use the MNIST dataset which is the 'Hello world' problem of deep learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amZfSNv8WwTA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfjjxqk-4-VY"
      },
      "source": [
        "I always like to start my jupternotebooks with this code because it fits the display window to my screen."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oq3zQaj94-Vf",
        "outputId": "c5d0ab9b-4d86-4137-b7e5-8955daae221c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "from IPython.core.display import display, HTML\n",
        "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>.container { width:95% !important; }</style>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTIiJaMH4-We"
      },
      "source": [
        "### This tutrial was adapted from Deep Learning with Python Chapter 2 Chollet, F. (2017). Deep Learning with Python (1st ed.). Greenwich, CT, USA: Manning Publications Co."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7J8caRE4-Wv"
      },
      "source": [
        "Start with some definitions.\n",
        "Numerical data in an array are called tensors.  https://en.wikipedia.org/wiki/Tensor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYhqLSfB4-W5"
      },
      "source": [
        "Scalars are 0 dimensional tensors (a single digit). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sq1dfmTjXx1r",
        "outputId": "77c5b7eb-180d-4537-ed8f-9281e99adb05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import numpy as np\n",
        "x = np.array(12)\n",
        "print('The value of x is', x)\n",
        "print('The dimension of this tensor is', x.ndim) # 0 dimensions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The value of x is 12\n",
            "The dimension of this tensor is 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yd6j127g4-Xg"
      },
      "source": [
        "A 1 dimensional tensor is also called a vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iWxjAcgYF2H",
        "outputId": "de643693-71a9-4275-ae1d-41f8d3dc07d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "x = np.array([12, 1, 2, 3]) #create a vector\n",
        "print('The value of x is', x)\n",
        "print('The dimention of this tensor is', x.ndim) # 1 dimensions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The value of x is [12  1  2  3]\n",
            "The dimention of this tensor is 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZnkKqX74-YS"
      },
      "source": [
        "A 2 dimensional tensor is also called a matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kw6vcniRYMga",
        "outputId": "78a2b71b-cee4-4750-8442-4ab7664530c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "x = np.array([[12, 1, 2, 3],\n",
        "              [5, 6, 7, 8,],\n",
        "              [10, 11, 12, 12]])\n",
        "print('The value of x is', x) # Print the 3 x 4 matrix\n",
        "print('The dimension of this tensor is', x.ndim) # 2 dimensions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The value of x is [[12  1  2  3]\n",
            " [ 5  6  7  8]\n",
            " [10 11 12 12]]\n",
            "The dimension of this tensor is 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDXBkNgF4-ZH"
      },
      "source": [
        "We can create n dimensional tensors easily, although they become difficult to visualize.\n",
        "This 3D tensor is like a cube of data.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7unoEvdhYbYR",
        "outputId": "55460ca1-3057-4355-f805-c6b460274d7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "x = np.array([[[12, 1, 2, 3],\n",
        "               [5, 6, 7, 8,],\n",
        "               [10, 11, 12, 12]],\n",
        "              [[2, 2, 2, 2,],\n",
        "               [3,3,3,3],\n",
        "               [4,4,4,4]],\n",
        "              [[5,5,5,5],\n",
        "               [6,6,6,6],\n",
        "               [7,7,7,7]]])\n",
        "print('The value of x is', x)\n",
        "print('The dimension of this tensor is', x.ndim) # 3 dimensional array"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The value of x is [[[12  1  2  3]\n",
            "  [ 5  6  7  8]\n",
            "  [10 11 12 12]]\n",
            "\n",
            " [[ 2  2  2  2]\n",
            "  [ 3  3  3  3]\n",
            "  [ 4  4  4  4]]\n",
            "\n",
            " [[ 5  5  5  5]\n",
            "  [ 6  6  6  6]\n",
            "  [ 7  7  7  7]]]\n",
            "The dimension of this tensor is 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QrNkyOM4-Z0"
      },
      "source": [
        "#### Reshaping tensors is important concept to understand.  We can reshape a tensor as long as it has the same number of coefficients as the initial tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5jul5ly4-Z6",
        "outputId": "6f822146-f91f-4300-d700-48f6bc5fa463",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "x = x.reshape(3*3*4,1)\n",
        "print(x)\n",
        "x = x.reshape(4, 3*3)\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[12]\n",
            " [ 1]\n",
            " [ 2]\n",
            " [ 3]\n",
            " [ 5]\n",
            " [ 6]\n",
            " [ 7]\n",
            " [ 8]\n",
            " [10]\n",
            " [11]\n",
            " [12]\n",
            " [12]\n",
            " [ 2]\n",
            " [ 2]\n",
            " [ 2]\n",
            " [ 2]\n",
            " [ 3]\n",
            " [ 3]\n",
            " [ 3]\n",
            " [ 3]\n",
            " [ 4]\n",
            " [ 4]\n",
            " [ 4]\n",
            " [ 4]\n",
            " [ 5]\n",
            " [ 5]\n",
            " [ 5]\n",
            " [ 5]\n",
            " [ 6]\n",
            " [ 6]\n",
            " [ 6]\n",
            " [ 6]\n",
            " [ 7]\n",
            " [ 7]\n",
            " [ 7]\n",
            " [ 7]]\n",
            "[[12  1  2  3  5  6  7  8 10]\n",
            " [11 12 12  2  2  2  2  3  3]\n",
            " [ 3  3  4  4  4  4  5  5  5]\n",
            " [ 5  6  6  6  6  7  7  7  7]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihVQabEo4-aS"
      },
      "source": [
        "##### Tensors have three atributes: number of axis (dimensions), shape (length of each axis), and data type (typically we will use float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUA1N4pS4-aY"
      },
      "source": [
        "Load the MNIST library which is part of Keras.  MNIST stands for Modified National Institute of Technology. https://en.wikipedia.org/wiki/MNIST_database. It is a collection of 60,000 training and 10,000 test images of the digits 0-9. https://keras.io/datasets/. We will build a deep learning nerual net model to classify the 10 digits. This is the 'Hello World' problem of deep learning. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AG-iMB8P3DZ"
      },
      "source": [
        "# From the tensorflow data sets import MNIST \n",
        "from tensorflow.keras.datasets import mnist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Efu6_zaQKtQ"
      },
      "source": [
        "(train_images, train_labels),(test_images, test_labels) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYu3aOo4Qn9R",
        "outputId": "aa03af7c-053f-484a-8730-570ae49c680a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_images.shape #60,000 images that are 28 pixles by 28 pixles"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kw_ZUbC9zd6D"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73Jt87YRZBXe",
        "outputId": "94615f91-b199-4472-f19d-35de64f4d4cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_images.ndim #3D tensor"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_fgMe2h4-bm",
        "outputId": "5a5fa13d-eb4b-4e9d-b894-efcce616e5cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('The maximum value in the array is', train_images.max()) # The maximum value in the array is 255\n",
        "print('he minimum value in the array is', train_images.min()) # The minimum value in the array is 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The maximum value in the array is 255\n",
            "he minimum value in the array is 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACNHKDMhZMtH"
      },
      "source": [
        "# Get the shape, dimensions, max and min value of the test images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvcS2anBQ8cd",
        "outputId": "8198ad13-71ea-4822-e02c-819621a9506c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print('test image shape:', test_images.shape)\n",
        "print('number of dimensions:', test_images.ndim)\n",
        "print('maximum value', test_images.max())\n",
        "print('minimum value:', test_images.min())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test image shape: (10000, 28, 28)\n",
            "number of dimensions: 3\n",
            "maximum value 255\n",
            "minimum value: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAWThxtY4-co"
      },
      "source": [
        "In general the first axis in a tensor is the samples, the second axis is height, the third axis is the width, and the fourth is color channels (RGB = 3 & BW = 1)\n",
        "So image data will be a 4D tensor [samples, height, width, channels] the MNIST data is 3D bacause the color channel is black and white and thus = 1\n",
        "Video data will be a 5D tensor [samples, frames, height, width, channels]. By convention, time series data will be placed on the secod axis when present"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kavsqyWG4-cZ"
      },
      "source": [
        "Let's view one of the images.  We need to import matplotlib to view the digits "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwEiakpiZXnf"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvYknn0hZf51",
        "outputId": "2a1b3ee8-b139-401f-8960-912ca35d2ef3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "digit = train_images[1] # Select the fouth sample.\n",
        "plt.imshow(digit, cmap=plt.cm.binary) # Show the sample.  cmap is the color map.  We will keep it black and white (binary)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSBcnrgsRPJ3"
      },
      "source": [
        " # Import models and layers from tensorflow \n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8lxhcrHRV0x"
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Dense(512, activation='relu',input_shape=(28 * 28,)))\n",
        "model.add(layers.Dense(10, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcixP8_xR5j7"
      },
      "source": [
        "model.compile(optimizer = 'adam',\n",
        "               loss = 'categorical_crossentropy',\n",
        "               metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEeckA5ESIMB",
        "outputId": "8c357c8d-4815-4372-cbad-3907403473c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_images =  train_images.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype('float32')/train_images.max()\n",
        "\n",
        "print(train_images.ndim)\n",
        "\n",
        "test_images =  test_images.reshape((10000, 28 * 28))\n",
        "test_images = test_images.astype('float32')/test_images.max()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Crqw7E-x4-eh",
        "outputId": "ee159db5-7a5e-4ede-bfcf-9513e5fd8f2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "plt.imshow(train_images.reshape((60000,28,28))[4], cmap=plt.cm.binary)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f1f72aedd30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bw_1wSzI4-ex",
        "outputId": "d75a97f9-4a2a-4c08-e303-94d608a10105",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print('train image shape:', train_images.shape)\n",
        "print('number of dimensions:', train_images.ndim)\n",
        "print('maximum value', train_images.max())\n",
        "print('minimum value:', train_images.min())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train image shape: (60000, 784)\n",
            "number of dimensions: 2\n",
            "maximum value 1.0\n",
            "minimum value: 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44PHpAPRUVyV"
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeczsZHUVDQx"
      },
      "source": [
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w90ZrgWhVPC1",
        "outputId": "223277f8-d4df-4f9b-9e8c-dd74c98100af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        " model.fit(train_images, train_labels, epochs = 5, batch_size = 120) \n",
        "# Batch size is how many images to process at once. Epoch is how many times to repeat the analysis.  Each epoch performs 500 gradient updates (60,000/120 = 500)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 0.2639 - accuracy: 0.9260\n",
            "Epoch 2/5\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 0.1058 - accuracy: 0.9686\n",
            "Epoch 3/5\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 0.0684 - accuracy: 0.9799\n",
            "Epoch 4/5\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 0.0482 - accuracy: 0.9856\n",
            "Epoch 5/5\n",
            "500/500 [==============================] - 5s 11ms/step - loss: 0.0360 - accuracy: 0.9897\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1f729d9748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHqqd_YYVdz3",
        "outputId": "ee9183b8-6c11-41ab-9503-135af779aab8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print('test_acc:', test_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0676 - accuracy: 0.9782\n",
            "test_acc: 0.9782000184059143\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIRCQyZ2F24o"
      },
      "source": [
        "# Your Turn\n",
        "####  Build 3 different models with activations 'relu', 'tanh', and 'sigmoid'.  The last activation must be 'softmax' since we have a multiclass problem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FYnYZJ6z1X3"
      },
      "source": [
        "np.random.seed(486)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgHnMI6T4-f6"
      },
      "source": [
        "relu_model = models.Sequential()\n",
        "relu_model.add(layers.Dense(512, activation='relu',input_shape=(28 * 28,)))\n",
        "relu_model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "tanh_model = models.Sequential()\n",
        "tanh_model.add(layers.Dense(512, activation='tanh',input_shape=(28 * 28,)))\n",
        "tanh_model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "\n",
        "sigmoid_model = models.Sequential()\n",
        "sigmoid_model.add(layers.Dense(512, activation='sigmoid',input_shape=(28 * 28,)))\n",
        "sigmoid_model.add(layers.Dense(10, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnUDSgXk4-gE"
      },
      "source": [
        "#### Compile your model.  Use categorical_crossentropyy since this problem is a multiclassification problem. Metrics will be 'accuracy' and optimizer will be 'adam'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhHGydeC4-gH"
      },
      "source": [
        "relu_model.compile(optimizer = 'adam',\n",
        "                   loss = 'categorical_crossentropy',\n",
        "                   metrics = ['accuracy'])\n",
        "\n",
        "tanh_model.compile(optimizer = 'adam',\n",
        "                   loss = 'categorical_crossentropy',\n",
        "                   metrics = ['accuracy'])\n",
        "\n",
        "sigmoid_model.compile(optimizer = 'adam',\n",
        "                      loss = 'categorical_crossentropy',\n",
        "                      metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7uSP2vm4-gR"
      },
      "source": [
        "#### Fit the models with epochs = 5 and  batch_size = 150"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9qFLRMA4-gT",
        "outputId": "f00c955a-b6bc-4d20-f17f-c3142394b666",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "source": [
        "relu_model.fit(train_images, train_labels, epochs = 5, batch_size = 150)\n",
        "tanh_model.fit(train_images, train_labels, epochs = 5, batch_size = 150)\n",
        "sigmoid_model.fit(train_images, train_labels, epochs = 5, batch_size = 150)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "400/400 [==============================] - 4s 10ms/step - loss: 0.2766 - accuracy: 0.9232\n",
            "Epoch 2/5\n",
            "400/400 [==============================] - 4s 10ms/step - loss: 0.1132 - accuracy: 0.9676\n",
            "Epoch 3/5\n",
            "400/400 [==============================] - 4s 10ms/step - loss: 0.0750 - accuracy: 0.9776\n",
            "Epoch 4/5\n",
            "400/400 [==============================] - 4s 10ms/step - loss: 0.0536 - accuracy: 0.9840\n",
            "Epoch 5/5\n",
            "400/400 [==============================] - 5s 12ms/step - loss: 0.0399 - accuracy: 0.9883\n",
            "Epoch 1/5\n",
            "400/400 [==============================] - 4s 10ms/step - loss: 0.3335 - accuracy: 0.9028\n",
            "Epoch 2/5\n",
            "400/400 [==============================] - 4s 10ms/step - loss: 0.1863 - accuracy: 0.9462\n",
            "Epoch 3/5\n",
            "400/400 [==============================] - 4s 10ms/step - loss: 0.1276 - accuracy: 0.9631\n",
            "Epoch 4/5\n",
            "400/400 [==============================] - 4s 10ms/step - loss: 0.0967 - accuracy: 0.9720\n",
            "Epoch 5/5\n",
            "400/400 [==============================] - 5s 12ms/step - loss: 0.0734 - accuracy: 0.9786\n",
            "Epoch 1/5\n",
            "400/400 [==============================] - 4s 10ms/step - loss: 0.4686 - accuracy: 0.8770\n",
            "Epoch 2/5\n",
            "400/400 [==============================] - 4s 10ms/step - loss: 0.2561 - accuracy: 0.9269\n",
            "Epoch 3/5\n",
            "400/400 [==============================] - 4s 10ms/step - loss: 0.2033 - accuracy: 0.9419\n",
            "Epoch 4/5\n",
            "400/400 [==============================] - 4s 10ms/step - loss: 0.1663 - accuracy: 0.9523\n",
            "Epoch 5/5\n",
            "400/400 [==============================] - 4s 10ms/step - loss: 0.1363 - accuracy: 0.9604\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1f6f1ffe80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WB4RPCz54-gb"
      },
      "source": [
        "#### Test the accuracy of the model on the test images and test labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7V6DjwV4-gc",
        "outputId": "2ef63961-97f5-465f-f0b9-d234e447f6ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "test_loss, test_acc = relu_model.evaluate(test_images, test_labels)\n",
        "print('relu_test_acc:', test_acc)\n",
        "\n",
        "test_loss, test_acc = tanh_model.evaluate(test_images, test_labels)\n",
        "print('tanh_test_acc:', test_acc)\n",
        "\n",
        "test_loss, test_acc = sigmoid_model.evaluate(test_images, test_labels)\n",
        "print('sigmoid_model_test_acc:', test_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0635 - accuracy: 0.9810\n",
            "relu_test_acc: 0.9810000061988831\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0925 - accuracy: 0.9709\n",
            "tanh_test_acc: 0.9708999991416931\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1321 - accuracy: 0.9612\n",
            "sigmoid_model_test_acc: 0.9611999988555908\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbR0ds5G4-gm"
      },
      "source": [
        "#### which activation gave the highest accuracy?\n",
        "\n",
        "***The model that performed the best above is the 'relu' model.***\n",
        "\n",
        "### Using the acitvation that gave the highest accuracy build 3 different models with 3 hidden layers and varying units in each hidden layer.  The first and output layers are given to you.  Use the same 'relu' activation fuction on the input and hidden layers throughout so you can compare how adding nodes and hidden layers effect your model performance with the same activation function.\n",
        "### By convention hidden layers are built in orders of 2^x.  For example: 2, 4, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096, etc. Built three models where the nodes (units) grow, stay consistant, and decrease."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTh369rD4-gr"
      },
      "source": [
        "# First model have the nodes increase from 2\n",
        "h1_model = models.Sequential()\n",
        "h1_model.add(layers.Dense(2, activation='relu',input_shape=(28 * 28,)))\n",
        "h1_model.add(layers.Dense(4, activation='relu'))\n",
        "h1_model.add(layers.Dense(16, activation='relu'))\n",
        "h1_model.add(layers.Dense(256, activation='relu'))\n",
        "h1_model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# Second model have the nodes stay consistant at 512\n",
        "h2_model = models.Sequential()\n",
        "h2_model.add(layers.Dense(512, activation='relu',input_shape=(28 * 28,)))\n",
        "h2_model.add(layers.Dense(512, activation='relu'))\n",
        "h2_model.add(layers.Dense(512, activation='relu'))\n",
        "h2_model.add(layers.Dense(512, activation='relu'))\n",
        "h2_model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# Third model, have the nodes decrease from 2048\n",
        "h3_model = models.Sequential()\n",
        "h3_model.add(layers.Dense(2048, activation='relu',input_shape=(28 * 28,)))\n",
        "h3_model.add(layers.Dense(1024, activation='relu'))\n",
        "h3_model.add(layers.Dense(512, activation='relu'))\n",
        "h3_model.add(layers.Dense(256, activation='relu'))\n",
        "h3_model.add(layers.Dense(10, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EY-vLrzS4-g1"
      },
      "source": [
        "#### Complie the three models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvYLN-Ld4-g3"
      },
      "source": [
        "h1_model.compile(optimizer='adam',\n",
        "                 loss='categorical_crossentropy',\n",
        "                 metrics=['accuracy'])\n",
        "\n",
        "h2_model.compile(optimizer='adam',\n",
        "                 loss='categorical_crossentropy',\n",
        "                 metrics=['accuracy'])\n",
        "\n",
        "h3_model.compile(optimizer='adam',\n",
        "                 loss='categorical_crossentropy',\n",
        "                 metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRMZ56yI4-hF"
      },
      "source": [
        "#### Fit the models with epochs = 5 and  batch_size = 150"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wO_mcJ9x4-hI",
        "outputId": "55ab3849-052a-442b-a5e3-9f43f287a2e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "source": [
        "h1_model.fit(train_images, train_labels, epochs = 5, batch_size = 150)\n",
        "h2_model.fit(train_images, train_labels, epochs = 5, batch_size = 150)\n",
        "h3_model.fit(train_images, train_labels, epochs = 5, batch_size = 150)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 1.4159 - accuracy: 0.4458\n",
            "Epoch 2/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 1.0255 - accuracy: 0.6402\n",
            "Epoch 3/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.9304 - accuracy: 0.6786\n",
            "Epoch 4/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.9011 - accuracy: 0.6900\n",
            "Epoch 5/5\n",
            "400/400 [==============================] - 2s 4ms/step - loss: 0.8869 - accuracy: 0.6964\n",
            "Epoch 1/5\n",
            "400/400 [==============================] - 14s 34ms/step - loss: 0.2218 - accuracy: 0.9329\n",
            "Epoch 2/5\n",
            "400/400 [==============================] - 13s 33ms/step - loss: 0.0866 - accuracy: 0.9729\n",
            "Epoch 3/5\n",
            "400/400 [==============================] - 15s 37ms/step - loss: 0.0600 - accuracy: 0.9816\n",
            "Epoch 4/5\n",
            "400/400 [==============================] - 13s 34ms/step - loss: 0.0456 - accuracy: 0.9858\n",
            "Epoch 5/5\n",
            "400/400 [==============================] - 15s 36ms/step - loss: 0.0382 - accuracy: 0.9882\n",
            "Epoch 1/5\n",
            "400/400 [==============================] - 45s 112ms/step - loss: 0.2005 - accuracy: 0.9382\n",
            "Epoch 2/5\n",
            "400/400 [==============================] - 45s 111ms/step - loss: 0.0873 - accuracy: 0.9729\n",
            "Epoch 3/5\n",
            "400/400 [==============================] - 46s 114ms/step - loss: 0.0586 - accuracy: 0.9818\n",
            "Epoch 4/5\n",
            "400/400 [==============================] - 45s 112ms/step - loss: 0.0464 - accuracy: 0.9858\n",
            "Epoch 5/5\n",
            "400/400 [==============================] - 46s 114ms/step - loss: 0.0372 - accuracy: 0.9889\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1f6b4f3860>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0Kcmj6x4-hU"
      },
      "source": [
        "#### Test the accuracy of the 3 models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRUw9R5F4-ha",
        "outputId": "f607131a-6de2-4a10-a423-3680a7e252df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "test_loss, test_acc = h1_model.evaluate(test_images, test_labels)\n",
        "print('h1_model_test_acc:', test_acc)\n",
        "\n",
        "test_loss, test_acc = h2_model.evaluate(test_images, test_labels)\n",
        "print('h2_model_test_acc:', test_acc)\n",
        "\n",
        "test_loss, test_acc = h3_model.evaluate(test_images, test_labels)\n",
        "print('h3_model_model_model_test_acc:', test_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 0s 852us/step - loss: 0.8697 - accuracy: 0.7071\n",
            "h1_model_test_acc: 0.707099974155426\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0724 - accuracy: 0.9788\n",
            "h2_model_test_acc: 0.9787999987602234\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0741 - accuracy: 0.9805\n",
            "h3_model_model_model_test_acc: 0.9804999828338623\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-fHqdpQ4-hm"
      },
      "source": [
        "#### Which model gave the highest accuracy?\n",
        "\n",
        "**The three models implemented above were one that scaled by squaring the nodes of previous layer to select the new nodes layer, one that left all three layers of nodes the same size, and one that reduced the nodes of each layer by half of the previous layer. The last model that went from 2048 > 1024 > 512 > 256 performed the best, although only by about .3% more than the model that had consistant node size. The model in which the nodes increased from one layer to the next performed significantly worse, and even worse than a model with only one layer of 512 nodes. This could be because the first layer with four nodes provided such a ppor initial separation for the classifiers to be captured accurately.**\n",
        "\n",
        "**One interesting aspect is the worst performing model was the only model that had a lower accuracy on the training data than the test data, suggesting it is the only model not subject to overfitting.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtlxQShJ8Io8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}